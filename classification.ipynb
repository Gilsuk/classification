{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bitc3ef7b825566454f946541eea1d7a2c1",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('./attach_02.xlsx')\n",
    "# 데이터 파일 로드\n",
    "print(data[:3])\n",
    "# 데이터 형식 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['No']\n",
    "# No 열 삭제\n",
    "labels = data['신고유형'].unique()\n",
    "# 신고유형 원문 저장\n",
    "data['신고유형'] = data['신고유형'].replace(labels, list(range(0, len(labels))))\n",
    "# 신고유형을 정수로 변환\n",
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "import re\n",
    "# 형태소 분석기, 정규식 임포트\n",
    "kkma = Kkma()\n",
    "matcher = re.compile(r'^[가-힣]+$')\n",
    "# 형태소 분석기 생성, 한글로만 이루어진 문자열 추출하는 정규식 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = []\n",
    "for number in data['신고유형']:\n",
    "    y_data.append([number])\n",
    "\n",
    "X_data = []\n",
    "# 한글로만 이루어진 문자열 추출\n",
    "for sentence in data['내용']:\n",
    "    temp = []\n",
    "    nouns = kkma.nouns(sentence)\n",
    "    for noun in nouns:\n",
    "        if matcher.match(noun):\n",
    "            temp.append(noun)\n",
    "    X_data.append(temp)\n",
    "# 토큰화하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "# 토큰을 정수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "print('제한할 단어 집합의 크기: %s'%(total_cnt - rare_cnt + 1))\n",
    "\n",
    "# 1번만 등장한 단어를 분석에서 제외함\n",
    "# https://wikidocs.net/44249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer  = Tokenizer(total_cnt - rare_cnt + 1)\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "X_data = tokenizer.texts_to_sequences(X_data)\n",
    "# 내용문장을 정수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_data = pad_sequences(X_data, maxlen = 150)\n",
    "# 내용의 길이를 150으로 맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLen = round(len(data) * 0.8)\n",
    "X_train = X_data[:trainLen]\n",
    "X_test = X_data[trainLen:]\n",
    "y_train = y_data[:trainLen]\n",
    "y_test = y_data[trainLen:]\n",
    "# 8:2 비율로 학습데이터와 검증데이터를 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "# 나이브 베이즈 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_ot = to_categorical(y_train)\n",
    "y_test_ot = to_categorical(y_test)\n",
    "# 레이블 데이터 원-핫 인코딩\n",
    "\n",
    "rnn = Sequential()\n",
    "rnn.add(Embedding(total_cnt - rare_cnt + 1,  32, mask_zero=True))\n",
    "rnn.add(LSTM(32))\n",
    "rnn.add(Dense(len(labels), activation='softmax'))\n",
    "rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "rnn.summary()\n",
    "# rnn 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "rnn.fit(X_train, y_train_ot, validation_data=(X_test, y_test_ot), epochs=200, batch_size=128, verbose=1)\n",
    "# LSTM 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encodeSentence(sentence):\n",
    "    temp = []\n",
    "    nouns = kkma.nouns(sentence)\n",
    "    for noun in nouns:\n",
    "        if matcher.match(noun):\n",
    "            temp.append(noun)\n",
    "\n",
    "    temp = tokenizer.texts_to_sequences([temp])\n",
    "    temp = pad_sequences(temp, maxlen = 150)\n",
    "\n",
    "    return temp\n",
    "\n",
    "def predictByNB(encodedSentence):\n",
    "    return labels[nb.predict(encodedSentence)[0]]\n",
    "\n",
    "def predictByRNN(encodedSentence):\n",
    "    pred = rnn.predict(encodedSentence)\n",
    "    labelIndex = np.argmax(pred[0])\n",
    "    return labels[labelIndex]\n",
    "\n",
    "def predict(sentence):\n",
    "    encodedSentence = encodeSentence(sentence)\n",
    "    nb = predictByNB(encodedSentence)\n",
    "    rnn = predictByRNN(encodedSentence)\n",
    "    print('나이브베지안:\\t%s\\nRNN 예측:\\t%s'%(nb, rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testStr = '직업훈련학원 대표 F는 지방자치단체로부터 위탁받은 지역실업자훈련과정을 운영하면서 훈련생이 아닌 자들이 마치 훈련받은 것처럼 서류를 허위로 꾸며매월 훈련비를 편취하였고, 학원에 훈련생들의 명의만을 허위로 등록한 후 지방자치단체로부터 매월 지급받는 훈련수당과 근로자 수강지원비를 편취함.'\n",
    "\n",
    "predict(testStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testStr = '모 공직유관단체 직원 A 등은 지역본부장 B의 지시로 지역본부장의 가족이 운영하는 가게에서 선물을 구입하고, 사업의 원활한 추진을위하여 업무관계자에게 이를 제공하는 과정에서 본부장의 부당한 지시를 거부하거나 행동강령책임관과 상담하지 않고 그대로 따름'\n",
    "\n",
    "predict(testStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testStr = '모 중앙행정기관 사무관 A는 소속 기관의 무기계약직 채용심사 과정에서 자신의 조카가 응시한 사실을 알면서도 심사절차를 회피하지 않고 면접 심사위원으로 참여'\n",
    "\n",
    "predict(testStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testStr = '중앙부처 소속 국장 B의 자녀 A가 ○○지방자치단체에서 실시하는 변호사 자격소지자 제한경쟁 채용시험에 응시하였음. 국장 B는 자녀 A 몰래 면접위원인 인사과장 C에게 면접시험 점수를 높게 주어 합격시켜 달라는 청탁을 하였고 면접위원으로 참석한 인사과장 C가 면접시험 점수를 높게 주어 자녀 A가 합격한 경우'\n",
    "\n",
    "predict(testStr)"
   ]
  }
 ]
}